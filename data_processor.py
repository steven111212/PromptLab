#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è³‡æ–™è™•ç†ç¨‹å¼ï¼šå¾è³‡æ–™åº«è®€å–è³‡æ–™ä¸¦ç”ŸæˆåŒ…å«çµ±è¨ˆæŒ‡æ¨™çš„åˆ†æå ±å‘Š

åŠŸèƒ½ï¼š
1. å¾ SQLite è³‡æ–™åº«è®€å–è©•ä¼°çµæœ
2. æ ¹æ“š eval_id åˆ†å‰²è³‡æ–™ä¸¦å„²å­˜ç‚ºå€‹åˆ¥ CSV æª”æ¡ˆ
3. è¨ˆç®—æ¯å€‹ eval_id çš„é€šéç‡å’Œè³‡æ–™é›†æ•¸é‡
4. ç”ŸæˆåŒ…å«çµ±è¨ˆæŒ‡æ¨™çš„æœ€çµ‚åˆ†ææª”æ¡ˆ
"""

import pandas as pd
import sqlite3
import os
import re


def clean_filename(filename):
    """æ¸…ç†æª”æ¡ˆåç¨±ä¸­çš„ç„¡æ•ˆå­—ç¬¦"""
    invalid_chars = r'[<>:"/\\|?*]'
    cleaned = re.sub(invalid_chars, '_', filename)
    return cleaned


def process_evaluation_data():
    """ä¸»è¦è™•ç†å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹è³‡æ–™è™•ç†æµç¨‹...")
    
    # ================================
    # æ­¥é©Ÿ 1: é€£æ¥è³‡æ–™åº«ä¸¦è®€å–è³‡æ–™
    # ================================
    print("\nğŸ“Š æ­¥é©Ÿ 1: å¾è³‡æ–™åº«è®€å–è³‡æ–™...")
    
    try:
        conn = sqlite3.connect(r'C:\Users\stevenwu\.promptfoo\promptfoo.db')
        df = pd.read_sql_query("SELECT * FROM eval_results", conn)
        df2 = pd.read_sql_query("SELECT * FROM evals", conn)
        conn.close()
        
        print(f"âœ… eval_results è³‡æ–™è¡¨: {len(df)} ç­†è³‡æ–™")
        print(f"âœ… evals è³‡æ–™è¡¨: {len(df2)} ç­†è³‡æ–™")
        
    except Exception as e:
        print(f"âŒ è³‡æ–™åº«é€£æ¥éŒ¯èª¤: {str(e)}")
        return None
    
    # ================================
    # æ­¥é©Ÿ 2: è³‡æ–™ç¯©é¸å’Œæº–å‚™
    # ================================
    
    print(f"âœ… ç¯©é¸å¾Œçš„è©•ä¼°çµæœ: {len(df)} ç­†è³‡æ–™")
    print(f"âœ… æè¿°è³‡æ–™: {len(df2)} ç­†è³‡æ–™")
    
    # ================================
    # æ­¥é©Ÿ 3: å‰µå»ºè³‡æ–™å¤¾çµæ§‹
    # ================================
    print("\nğŸ“ æ­¥é©Ÿ 3: å‰µå»ºè³‡æ–™å¤¾çµæ§‹...")
    
    os.makedirs('temp', exist_ok=True)
    os.makedirs('temp/eval_id', exist_ok=True)
    
    # ================================
    # æ­¥é©Ÿ 4: æ ¹æ“š eval_id åˆ†å‰²è³‡æ–™ä¸¦å„²å­˜
    # ================================
    print("\nâœ‚ï¸ æ­¥é©Ÿ 4: æ ¹æ“š eval_id åˆ†å‰²ä¸¦å„²å­˜ CSV æª”æ¡ˆ...")
    
    unique_eval_ids = df['eval_id'].unique()
    print(f"æ‰¾åˆ° {len(unique_eval_ids)} å€‹ä¸åŒçš„ eval_id")
    
    for eval_id in unique_eval_ids:
        # éæ¿¾å‡ºç‰¹å®š eval_id çš„è³‡æ–™
        df_subset = df[df['eval_id'] == eval_id]
        
        # æ¸…ç† eval_id ä½œç‚ºæª”æ¡ˆåç¨±
        clean_eval_id = clean_filename(str(eval_id))
        filename = f'temp/eval_id/{clean_eval_id}.csv'
        
        # å„²å­˜ CSV æª”æ¡ˆ
        df_subset.to_csv(filename, index=False, encoding='utf-8-sig')
        
        print(f"âœ… {eval_id}: {len(df_subset)} ç­†è³‡æ–™å·²å„²å­˜è‡³ {filename}")
    
    # ================================
    # æ­¥é©Ÿ 5: è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™ä¸¦å¢å¼·æè¿°è³‡æ–™
    # ================================
    print("\nğŸ“ˆ æ­¥é©Ÿ 5: è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™...")
    
    # è¤‡è£½æè¿°è³‡æ–™ä¸¦æ–°å¢æ¬„ä½
    df2_enhanced = df2.copy()
    df2_enhanced['pass_rate'] = 0.0
    df2_enhanced['dataset_count'] = 0
    
    # éæ­·æ¯å€‹ eval_id è¨ˆç®—çµ±è¨ˆè³‡æ–™
    for index, row in df2_enhanced.iterrows():
        eval_id = row['id']
        
        # æ¸…ç†æª”æ¡ˆåç¨±
        clean_eval_id = clean_filename(str(eval_id))
        csv_file_path = f'temp/eval_id/{clean_eval_id}.csv'
        
        try:
            # è®€å–å°æ‡‰çš„ CSV æª”æ¡ˆ
            eval_data = pd.read_csv(csv_file_path)
            
            # è¨ˆç®—è³‡æ–™é›†æ•¸é‡ï¼ˆç¸½è¡Œæ•¸ï¼‰
            dataset_count = len(eval_data)
            
            # è¨ˆç®— pass_rateï¼ˆsuccess æ¬„ä½ç‚º 1 çš„æ¯”ä¾‹ï¼‰
            success_count = eval_data['success'].sum()
            pass_rate = success_count / dataset_count if dataset_count > 0 else 0.0
            
            # æ›´æ–° dataframe
            df2_enhanced.at[index, 'pass_rate'] = round(pass_rate, 4)
            df2_enhanced.at[index, 'dataset_count'] = dataset_count
            
            print(f"âœ… {eval_id}: è³‡æ–™é›†æ•¸é‡={dataset_count}, é€šéæ•¸é‡={success_count}, é€šéç‡={pass_rate:.4f}")
            
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {csv_file_path}")
        except Exception as e:
            print(f"âŒ è™•ç† {eval_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
    
    # ================================
    # æ­¥é©Ÿ 6: å„²å­˜æœ€çµ‚çµæœä¸¦é¡¯ç¤ºçµ±è¨ˆæ‘˜è¦
    # ================================
    print("\nğŸ’¾ æ­¥é©Ÿ 6: å„²å­˜æœ€çµ‚çµæœ...")
    
    # å„²å­˜åŒ…å«çµ±è¨ˆæŒ‡æ¨™çš„æœ€çµ‚æª”æ¡ˆ
    output_file = 'temp/df2_enhanced.csv'
    df2_enhanced.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"âœ… åŒ…å«çµ±è¨ˆæŒ‡æ¨™çš„è³‡æ–™å·²å„²å­˜è‡³ {output_file}")
    
    # é¡¯ç¤ºçµ±è¨ˆæ‘˜è¦
    print("\n" + "="*50)
    print("ğŸ“Š æœ€çµ‚çµ±è¨ˆæ‘˜è¦")
    print("="*50)
    print(f"ç¸½å…±è™•ç†äº† {len(df2_enhanced)} å€‹ eval_id")
    print(f"å¹³å‡é€šéç‡: {df2_enhanced['pass_rate'].mean():.4f}")
    print(f"å¹³å‡è³‡æ–™é›†æ•¸é‡: {df2_enhanced['dataset_count'].mean():.1f}")
    print(f"æœ€é«˜é€šéç‡: {df2_enhanced['pass_rate'].max():.4f}")
    print(f"æœ€ä½é€šéç‡: {df2_enhanced['pass_rate'].min():.4f}")
    
    # æŒ‰é€šéç‡æ’åºé¡¯ç¤º
    print("\nğŸ† æŒ‰é€šéç‡æ’åº:")
    df_sorted = df2_enhanced.sort_values('pass_rate', ascending=False)
    print(df_sorted[['id', 'description', 'pass_rate', 'dataset_count']].to_string(index=False))
    
    print("\nğŸ‰ è³‡æ–™è™•ç†å®Œæˆï¼")
    print("ğŸ“ ç”Ÿæˆçš„æª”æ¡ˆ:")
    print(f"   - {output_file} (åŒ…å«çµ±è¨ˆæŒ‡æ¨™çš„æœ€çµ‚åˆ†ææª”æ¡ˆ)")
    print("   - temp/eval_id/*.csv (å„å€‹ eval_id çš„åˆ†å‰²æª”æ¡ˆ)")
    
    return df2_enhanced


if __name__ == "__main__":
    # åŸ·è¡Œä¸»è¦è™•ç†å‡½æ•¸
    result = process_evaluation_data()
    
    if result is not None:
        print(f"\nâœ¨ è™•ç†æˆåŠŸï¼æœ€çµ‚è³‡æ–™åŒ…å« {len(result)} ç­†è¨˜éŒ„")
    else:
        print("\nâŒ è™•ç†å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯")
